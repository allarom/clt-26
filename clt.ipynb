{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuyR1KVpq5db"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYT3YqSG-mFd",
        "outputId": "642fb1e2-a5da-469e-a51a-234235204883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (1.4.0)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Downloading murmurhash-1.0.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Downloading cymem-2.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Downloading preshed-3.0.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Downloading srsly-2.5.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
            "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
            "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (2.12.5)\n",
            "Requirement already satisfied: jinja2 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (80.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting typer>=0.24.0 (from typer-slim<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading typer-0.24.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
            "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
            "  Downloading smart_open-7.5.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: wrapt in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting click>=8.2.1 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=12.3.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (14.2.0)\n",
            "Collecting annotated-doc>=0.0.2 (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aptt@mediait.ch/miniconda3/envs/RS/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
            "Downloading spacy-3.8.11-cp311-cp311-macosx_11_0_arm64.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.13-cp311-cp311-macosx_11_0_arm64.whl (43 kB)\n",
            "Downloading murmurhash-1.0.15-cp311-cp311-macosx_11_0_arm64.whl (27 kB)\n",
            "Downloading preshed-3.0.12-cp311-cp311-macosx_11_0_arm64.whl (124 kB)\n",
            "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.2-cp311-cp311-macosx_11_0_arm64.whl (653 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.1/653.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.10-cp311-cp311-macosx_11_0_arm64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.6/770.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.3.3-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
            "Downloading typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\n",
            "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
            "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
            "Downloading smart_open-7.5.1-py3-none-any.whl (64 kB)\n",
            "Downloading typer-0.24.1-py3-none-any.whl (56 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: wasabi, tqdm, spacy-loggers, spacy-legacy, smart-open, shellingham, murmurhash, cymem, cloudpathlib, click, catalogue, blis, annotated-doc, srsly, preshed, typer, confection, typer-slim, thinc, weasel, spacy\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [spacy]m20/21\u001b[0m [spacy]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-doc-0.0.4 blis-1.3.3 catalogue-2.0.10 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 murmurhash-1.0.15 preshed-3.0.12 shellingham-1.5.4 smart-open-7.5.1 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 tqdm-4.67.3 typer-0.24.1 typer-slim-0.24.0 wasabi-1.1.3 weasel-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2QhtVEU6AjlD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re #regex expressions\n",
        "import ast #for tag list\n",
        "import unidecode # replacement of accented characters\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNPomRbIbJF"
      },
      "source": [
        "# Stage 1: Enhanced Data Cleaning, Preprocessing, and Exploratory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5cGZ9JnIp-o"
      },
      "source": [
        "## 1.1 Data Collection & Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xamkwk1nTIa"
      },
      "source": [
        "*Done by: Marisa  - Checked by: Alla*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knVwSfcqK9tA"
      },
      "source": [
        "### Data Import\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdDWQ62qbVp7"
      },
      "source": [
        "- In your Google Drive, create a folder \"CLT\" and upload the csv with its original name (downloaded from Kaggle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzhMwM4II_Y",
        "outputId": "a7319f85-e965-4680-dbc6-5eb8223d1dce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "zXmmXfryLgT4",
        "outputId": "d91d365a-601b-4e37-8d5b-e788cee0d0ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16527,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27029,\n        \"min\": 6,\n        \"max\": 109492,\n        \"num_unique_values\": 16527,\n        \"samples\": [\n          68763,\n          83125,\n          105024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16527,\n        \"samples\": [\n          \"A new way to make graphs more accessible to blind and low-vision readers\",\n          \"Upleveling Omnichannel: How AI Helps Contact Centers Move From Reactive to Proactive Service\",\n          \"The GenAI App Step You\\u2019 re Skimping On: Evaluations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 347,\n        \"samples\": [\n          \"2025-07-30\",\n          \"2025-01-03\",\n          \"2025-08-02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16518,\n        \"samples\": [\n          \"['The telecommunications landscape is evolving rapidly, and the Radio Access Network ( RAN) is at the forefront of this transformation. Once the battleground for radio innovation, the RAN space has reached an interesting point, effectively \\u201c closing \\u201d the radio game.', \\\"But don\\u2019 t worry, this isn\\u2019 t the end of innovation in Open RAN - it's just shifting gears.\\\", 'Enter the RAN Intelligent Controller ( RIC), the next stage of Open RAN, where software takes the lead.', 'Let\\u2019 s explore why RIC is the logical step in Open RAN innovation, how it aligns with Open RAN principles, and what makes it the way to move forward in making the network open and interoperable.', 'First, let\\u2019 s revisit Open RAN. Open RAN ( Open Radio Access Network) is about disaggregating the traditional, monolithic RAN architecture into more flexible and modular components. This allows telecom operators to mix and match hardware and software from different vendors, fostering innovation and competition. The core idea is to avoid vendor lock-in, reduce costs, and accelerate the deployment of new features and services.', 'Open RAN opened the floodgates for numerous vendors to bring their hardware ( and software) solutions to the table. But now, the radio innovation is leveling off. The big players embraced Open RAN, and opportunities for groundbreaking advancements in radio technology have dried up for smaller players.', 'With the radio game effectively \\u201c closed, \\u201d where does that leave us? The answer lies in the software \\u2013 specifically, in RIC, with the focus shifting to optimizing and managing these complex networks through intelligent and open software solutions.', 'RIC, or the RAN Intelligent Controller, is a software-defined component defined by the O-RAN Alliance. It controls and optimizes RAN functions, providing a vendor-agnostic platform for handling control and management planes. In simple terms, RIC is the brain of modern telecom networks, enabling them to operate more efficiently and intelligently.', 'Think of RIC as the conductor of a vast orchestra, ensuring every instrument ( or network component) plays in harmony. It comprises two primary controllers: Near-Real-Time RIC ( Near-RT RIC) and Non-Real-Time RIC ( Non-RT RIC). Near-RT RIC handles immediate, latency-sensitive tasks, while Non-RT RIC focuses on long-term strategic functions. Together, they form a comprehensive solution for network optimization and automation.', 'But why is RIC causing such a buzz? With the radio game closed, the real opportunity for startups and new players lies in developing innovative software solutions for the RIC which also acts as an app store for xApps and rApps. RIC, powered by predictive AI, offers a smarter way to handle the complexity of modern networks. It can foresee potential issues and adjust the network in real-time, ensuring everything runs smoothly.', \\\"To illustrate the impact of RIC, let's look at some real-world deployments. Deutsche Telekom, for example, has significantly enhanced network reliability and performance by leveraging predictive AI algorithms through RIC. They report a 30% reduction in network downtime and a 25% decrease in maintenance costs. This deployment has also led to a 20% improvement in overall network performance, demonstrating the practical benefits of RIC.\\\", \\\"AT & T has integrated RIC to dynamically optimize its spectrum resources. The predictive analytics capabilities of RIC enable real-time spectrum allocation based on demand, resulting in a 15% increase in spectrum utilization efficiency. Additionally, AT & T has seen a 10% reduction in congestion during peak times, highlighting the effectiveness of RIC's predictive features.\\\", \\\"Vodafone's implementation of RIC focuses on enhancing energy efficiency. By predicting traffic loads and adjusting power consumption, RIC helps Vodafone reduce its carbon footprint while maintaining high network performance. This initiative aligns with Vodafone's sustainability goals, achieving a 20% reduction in energy consumption and a 15% improvement in network performance consistency.\\\", 'So, why is RIC being hailed as the rebirth of Open RAN? The principles of Open RAN \\u2013 flexibility, interoperability, and innovation \\u2013 are embodied in the RIC\\u2019 s architecture and functionality. The RIC allows telecom operators to take full advantage of the disaggregated, modular nature of Open RAN by providing a powerful platform for software innovation.', 'Open RAN promised to break the stranglehold of a few dominant vendors and create a more competitive, dynamic ecosystem. While this has largely been achieved on the hardware, radio and server front, the real game-changer is now in automation, optimization and network management software. RIC represents the next logical step in this evolution. It brings the same principles of openness and interoperability to the control and management of RAN functions but with the added advantage of advanced AI and machine learning capabilities.', 'A key component of the RIC\\u2019 s success is the thriving ecosystem of xApps and rApps. These applications extend the functionality and capabilities of RIC, allowing for targeted optimizations and enhancements across the network. xApps ( applications for the Near-Real-Time RIC) handle tasks like traffic steering and load balancing, while rApps ( applications for the Non-Real-Time RIC) focus on longer-term strategic functions such as policy control and predictive maintenance.', 'Why is this ecosystem thriving? The modular nature of RIC means that developers can create specialized applications without worrying about underlying hardware compatibility. This encourages a broader range of players, including startups and new entrants, to contribute to the telecom ecosystem. The ability to quickly develop and deploy these applications enables rapid innovation cycles, addressing emerging challenges and optimizing network performance in real-time.', 'Companies are actively developing xApps and rApps to enhance RIC\\u2019 s capabilities. RIC xApps include solutions for traffic steering and network slicing, while rApps focus on managing non-real-time functions such as policy control and predictive maintenance. This collaborative effort is fostering innovation and ensuring that RIC remains at the cutting edge of network management. These apps are like specialized tools, each designed to tackle specific network challenges, and their development is driving a wave of innovation in the telecom industry.', 'Let\\u2019 s not forget the tangible benefits that RIC brings to the table. By predicting and addressing issues before they occur, RIC ensures smoother and more reliable network performance. Predictive maintenance and dynamic resource management lead to significant cost reductions, helping telecom operators save on maintenance and operational costs.', 'Furthermore, by optimizing power usage based on real-time traffic predictions, RIC contributes to substantial energy savings. This not only reduces operational costs but also supports sustainability initiatives. With RIC, networks can deliver more consistent and high-quality service. This translates to happier customers and a competitive edge for telecom operators.', 'Despite its benefits, integrating RIC and predictive AI into telecom networks presents several challenges. Data privacy is a major concern, as RIC processes vast amounts of sensitive information. Ensuring robust data protection measures and compliance with regulatory standards is essential. Additionally, integrating RIC with existing network infrastructure can be complex and resource-intensive. Overcoming compatibility issues and ensuring seamless interoperability are critical for successful deployment. The continuous need for AI model updates to remain accurate and relevant adds another layer of complexity.', 'As the technology matures, we can expect more robust and diverse xApps and rApps to emerge, addressing a broader range of network management challenges. The continuous evolution of cloud-native technologies will also play a crucial role in shaping the future of RIC, providing the flexibility and scalability needed to support next-generation networks.', 'In conclusion, as the radio game evolved, the spotlight shifts to RIC as the new frontier in telecom innovation. By leveraging predictive AI, RIC offers a smarter, more efficient way to manage and optimize modern networks. Its ability to enhance network performance, reduce costs, and improve customer experience makes it a game-changer in the industry.', 'The RIC ecosystem is growing, with significant contributions from major players and innovative startups alike.', 'While challenges remain, the potential benefits of RIC far outweigh the hurdles. As we move forward, RIC will undoubtedly play a crucial role in shaping the future of telecommunications, heralding a new era of intelligent, adaptive, and efficient networks. And the time will tell if government programs like DSIT and SBIR DOD can help new RIC startups bloom. I am optimistic and we are already seeing such blooms in ARIANE project by TIP.', 'The views expressed in this article belong solely to the author and do not represent The Fast Mode. While information provided in this post is obtained from sources believed by The Fast Mode to be reliable, The Fast Mode is not liable for any losses or damages arising from any information limitations, changes, inaccuracies, misrepresentations, omissions or errors contained therein. The heading is for ease of reference and shall not be deemed to influence the information presented.', 'Eugina, a female executive and an immigrant, started her telecom career as a secretary and now has gone on to become the CMO of the prominent industry organization, Telecom Infra Project ( TIP). She has over 20+ years of strategic marketing leadership experience, leading marketing and communications for small and Fortune 500 global technology companies like Starent and Cisco. Previously, she served as the VP of Marketing of the major telecom industry disruptor Parallel Wireless and was instrumental in creating the Open RAN market category. She is a well sought-after speaker at many technology and telecom events and webinars. She is a well-known telecom writer contributing to publications like The Fast Mode, RCR Wireless, Developing Telecoms and many others. She is also an inventor, holding 12 patents that include 5G and Open RAN. She is a founding member of Boston chapter of CHIEF, an organization for women in the C-Suite, to strengthen their leadership, magnify their influence, pave the way to bring others, cross-pollinate power across industries, and effect change from the top-down. Her passion is to help other women in tech to realize their full potential through mentorships, community engagement, and workshops. Her leadership development book \\u201c Unlimited: How to succeed in a workplace that was not designed for you \\u201d is due for release in May 2023. Ms. Jordan resides in Massachusetts with her husband, teenage son, and three rescue dogs. She loves theater and museums. She volunteers for dog rescues and programs that help underprivileged children and women. Ms. Jordan has a Master\\u2019 s in Teaching from Moscow Pedagogical University, and studied computer undergrad at CDI College in Toronto, Canada.', 'Eugina, a female executive and an immigrant, started her telecom career as a secretary and now has gone on to become the CMO of the prominent industry organization, Telecom Infra Project ( TIP).', 'She has over 20+ years of strategic marketing leadership experience, leading marketing and communications for small and Fortune 500 global technology companies like Starent and Cisco.', 'Previously, she served as the VP of Marketing of the major telecom industry disruptor Parallel Wireless and was instrumental in creating the Open RAN market category.', 'She is a well sought-after speaker at many technology and telecom events and webinars. She is a well-known telecom writer contributing to publications like The Fast Mode, RCR Wireless, Developing Telecoms and many others.', 'She is also an inventor, holding 12 patents that include 5G and Open RAN.', 'She is a founding member of Boston chapter of CHIEF, an organization for women in the C-Suite, to strengthen their leadership, magnify their influence, pave the way to bring others, cross-pollinate power across industries, and effect change from the top-down.', 'Her passion is to help other women in tech to realize their full potential through mentorships, community engagement, and workshops. Her leadership development book \\u201c Unlimited: How to succeed in a workplace that was not designed for you \\u201d is due for release in May 2023.', 'Ms. Jordan resides in Massachusetts with her husband, teenage son, and three rescue dogs. She loves theater and museums. She volunteers for dog rescues and programs that help underprivileged children and women.', 'Ms. Jordan has a Master\\u2019 s in Teaching from Moscow Pedagogical University, and studied computer undergrad at CDI College in Toronto, Canada.']\",\n          \"['Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More', 'Even as large language models ( LLMs) become ever more sophisticated and capable, they continue to suffer from hallucinations: Offering up inaccurate information, or, to put it more harshly, lying.', 'This can be particularly harmful in areas like healthcare, where wrong information can have dire results.', 'Mayo Clinic, one of the top-ranked hospitals in the U.S., has adopted a novel technique to address this challenge. To succeed, the medical facility must overcome the limitations of retrieval-augmented generation ( RAG). That\\u2019 s the process by which large language models ( LLMs) pull information from specific, relevant data sources. The hospital has employed what is essentially backwards RAG, where the model extracts relevant information, then links every data point back to its original source content.', 'Remarkably, this has eliminated nearly all data-retrieval-based hallucinations in non-diagnostic use cases \\u2014 allowing Mayo to push the model out across its clinical practice.', '\\u201c With this approach of referencing source information through links, extraction of this data is no longer a problem, \\u201d Matthew Callstrom, Mayo\\u2019 s medical director for strategy and chair of radiology, told VentureBeat.', 'Dealing with healthcare data is a complex challenge \\u2014 and it can be a time sink. Although vast amounts of data are collected in electronic health records ( EHRs), data can be extremely difficult to find and parse out.', 'Mayo\\u2019 s first use case for AI in wrangling all this data was discharge summaries ( visit wrap-ups with post-care tips), with its models using traditional RAG. As Callstrom explained, that was a natural place to start because it is simple extraction and summarization, which is what LLMs generally excel at.', '\\u201c In the first phase, we\\u2019 re not trying to come up with a diagnosis, where you might be asking a model, \\u2018 What\\u2019 s the next best step for this patient right now?\\u2019, \\u201d he said.', 'The danger of hallucinations was also not nearly as significant as it would be in doctor-assist scenarios; not to say that the data-retrieval mistakes weren\\u2019 t head-scratching.', '\\u201c In our first couple of iterations, we had some funny hallucinations that you clearly wouldn\\u2019 t tolerate \\u2014 the wrong age of the patient, for example, \\u201d said Callstrom. \\u201c So you have to build it carefully. \\u201d', 'While RAG has been a critical component of grounding LLMs ( improving their capabilities), the technique has its limitations. Models may retrieve irrelevant, inaccurate or low-quality data; fail to determine if information is relevant to the human ask; or create outputs that don\\u2019 t match requested formats ( like bringing back simple text rather than a detailed table).', 'While there are some workarounds to these problems \\u2014 like graph RAG, which sources knowledge graphs to provide context, or corrective RAG ( CRAG), where an evaluation mechanism assesses the quality of retrieved documents \\u2014 hallucinations haven\\u2019 t gone away.', 'This is where the backwards RAG process comes in. Specifically, Mayo paired what\\u2019 s known as the clustering using representatives ( CURE) algorithm with LLMs and vector databases to double-check data retrieval.', 'Clustering is critical to machine learning ( ML) because it organizes, classifies and groups data points based on their similarities or patterns. This essentially helps models \\u201c make sense \\u201d of data. CURE goes beyond typical clustering with a hierarchical technique, using distance measures to group data based on proximity ( think: data closer to one another are more related than those further apart). The algorithm has the ability to detect \\u201c outliers, \\u201d or data points that don\\u2019 t match the others.', 'Combining CURE with a reverse RAG approach, Mayo\\u2019 s LLM split the summaries it generated into individual facts, then matched those back to source documents. A second LLM then scored how well the facts aligned with those sources, specifically if there was a causal relationship between the two.', '\\u201c Any data point is referenced back to the original laboratory source data or imaging report, \\u201d said Callstrom. \\u201c The system ensures that references are real and accurately retrieved, effectively solving most retrieval-related hallucinations. \\u201d', 'Callstrom\\u2019 s team used vector databases to first ingest patient records so that the model could quickly retrieve information. They initially used a local database for the proof of concept ( POC); the production version is a generic database with logic in the CURE algorithm itself.', '\\u201c Physicians are very skeptical, and they want to make sure that they\\u2019 re not being fed information that isn\\u2019 t trustworthy, \\u201d Callstrom explained. \\u201c So trust for us means verification of anything that might be surfaced as content. \\u201d', 'The CURE technique has proven useful for synthesizing new patient records too. Outside records detailing patients\\u2019 complex problems can have \\u201c reams \\u201d of data content in different formats, Callstrom explained. This needs to be reviewed and summarized so that clinicians can familiarize themselves before they see the patient for the first time.', '\\u201c I always describe outside medical records as a little bit like a spreadsheet: You have no idea what\\u2019 s in each cell, you have to look at each one to pull content, \\u201d he said.', 'But now, the LLM does the extraction, categorizes the material and creates a patient overview. Typically, that task could take 90 or so minutes out of a practitioner\\u2019 s day \\u2014 but AI can do it in about 10, Callstrom said.', 'He described \\u201c incredible interest \\u201d in expanding the capability across Mayo\\u2019 s practice to help reduce administrative burden and frustration.', '\\u201c Our goal is to simplify the processing of content \\u2014 how can I augment the abilities and simplify the work of the physician? \\u201d he said.', 'Of course, Callstrom and his team see great potential for AI in more advanced areas. For instance, they have teamed with Cerebras Systems to build a genomic model that predicts what will be the best arthritis treatment for a patient, and are also working with Microsoft on an image encoder and an imaging foundation model.', 'Their first imaging project with Microsoft is chest X-rays. They have so far converted 1.5 million X-rays and plan to do another 11 million in the next round. Callstrom explained that it\\u2019 s not extraordinarily difficult to build an image encoder; the complexity lies in making the resultant images actually useful.', 'Ideally, the goals are to simplify the way Mayo physicians review chest X-rays and augment their analyses. AI might, for example, identify where they should insert an endotracheal tube or a central line to help patients breathe. \\u201c But that can be much broader, \\u201d said Callstrom. For instance, physicians can unlock other content and data, such as a simple prediction of ejection fraction \\u2014 or the amount of blood pumping out of the heart \\u2014 from a chest X ray.', '\\u201c Now you can start to think about prediction response to therapy on a broader scale, \\u201d he said.', 'Mayo also sees \\u201c incredible opportunity \\u201d in genomics ( the study of DNA), as well as other \\u201c omic \\u201d areas, such as proteomics ( the study of proteins). AI could support gene transcription, or the process of copying a DNA sequence, to create reference points to other patients and help build a risk profile or therapy paths for complex diseases.', '\\u201c So you basically are mapping patients against other patients, building each patient around a cohort, \\u201d Callstrom explained. \\u201c That\\u2019 s what personalized medicine will really provide: \\u2018 You look like these other patients, this is the way we should treat you to see expected outcomes.\\u2019 The goal is really returning humanity to healthcare as we use these tools. \\u201d', 'But Callstrom emphasized that everything on the diagnosis side requires a lot more work. It\\u2019 s one thing to demonstrate that a foundation model for genomics works for rheumatoid arthritis; it\\u2019 s another to actually validate that in a clinical environment. Researchers have to start by testing small datasets, then gradually expand test groups and compare against conventional or standard therapy.', '\\u201c You don\\u2019 t immediately go to, \\u2018 Hey, let\\u2019 s skip Methotrexate \\u201d [ a popular rheumatoid arthritis medication ], he noted.', 'Ultimately: \\u201c We recognize the incredible capability of these [ models ] to actually transform how we care for patients and diagnose in a meaningful way, to have more patient-centric or patient-specific care versus standard therapy, \\u201d said Callstrom. \\u201c The complex data that we deal with in patient care is where we\\u2019 re focused. \\u201d', 'If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.', 'Read our Privacy Policy', 'Thanks for subscribing. Check out more VB newsletters here.', 'An error occured.']\",\n          \"['California\\u2019 s new environmental, social, and governance ( ESG) regulations should come as no surprise to anyone \\u2014 the state is a long-time leader in passing ambitious climate policies. But this time around, its impact will likely be felt beyond the Golden State\\u2019 s borders.', 'While the reporting regulations only apply to companies that do business or operate in California, it\\u2019 s a strong sign that other states will follow suit with similar laws. In particular, New York is likely next. The state already has two bills ( S897A and S5437) in the process of passage. If those become laws, the impact will be widespread, as many international companies operate out of the state. Illinois and Washington are also preparing similar legislation.', 'For the past decade, a global movement has been pushing companies to prioritize ESG. The 2015 Paris Climate Agreement heightened a sense of urgency to avoid the most catastrophic impacts of human-caused climate change, and environmental groups, regulators, investors, and consumers have been pressing companies to do their part in combating climate change ever since. California\\u2019 s new regulations are a big first step in making it happen in the U.S.', 'With the regulations coming into effect as early as 2025, companies should prepare now by centralizing operational data, building the technology infrastructure necessary to monitor their efforts, and setting up strong internal controls to reach their ESG goals. Getting these areas in place quickly will be vital to avoid hefty penalties, fines, and reputational risk.', 'Three ESG bills were passed and signed into law in October 2023. Amendments to two of the bills were signed into law in September 2024, pushing the deadline for the California Air Resources Board ( CARB) to develop and adopt regulations regarding the reporting specifics of Scope 1, 2, and 3 emissions to July 1, 2025. The amended law also allows greenhouse gas ( GHG) emission reporting to be consolidated with the parent company instead of the original plan of requiring each subsidiary company to produce its own report.', 'Here\\u2019 s a breakdown of each bill and the organizations that will be subject to them.', 'Who is impacted: All private and public companies that do business or operate in California with revenues over $ 1 billion.', 'What the law means: Senate Bill 253 requires companies to publicly disclose their GHG emissions across Scope 1, 2, and 3.', 'Scope 1 refers to the direct emissions from a company\\u2019 s operations, and Scope 2 includes indirect emissions from energy purchases, such as electricity. These scopes require an annual report starting in 2026. Scope 3 refers to indirect emissions, like supply chain operations, transportation costs, or employee company travel. Reporting for Scope 3 will begin in 2027.', 'Keep in mind that there are still uncertainties around reporting criteria. CARB has until July 2025 to finalize the details.', 'Who is impacted: All private and public companies that do business or operate in California with revenues over $ 500 million.', 'What the law means: Senate Bill 261 requires companies to submit a climate-related financial risk report to CARB on January 1, 2026, and every two years afterward. This report must include how climate change could impact the company\\u2019 s model and financial plan and the strategies it plans to implement to combat these risks. The report must also be made publicly available on the company\\u2019 s website.', 'Who is impacted: U.S. and international companies operating or doing business in California that market, sell, or use voluntary carbon offsets ( VCOs) or make certain \\u201c zero-emission \\u201d or \\u201c reduced emission \\u201d claims.', 'What the law means: Assembly Bill 1305 requires companies to disclose on their websites specific carbon offset project details for VCOs, their accountability measures, and the calculation methods for verifying the accuracy of those measures.', 'For emission claims, companies need to disclose how they determined those claims to be accurate and provide measurements of their completion or progress toward achieving that goal.', 'California\\u2019 s new ESG regulations are part of a larger global effort to hold corporations accountable for their environmental and social impacts. Investors are also taking note of these efforts. If companies don\\u2019 t adjust and adapt to the shift toward better corporate sustainability, they may diminish public confidence, lose market value, and impact funding opportunities to drive long-term business growth.', 'Finance, procurement, and supply chain departments will play a critical role in helping their companies achieve compliance and avoid these penalties. Here are some of the ways each department may be impacted and the strategies they may adopt to prepare for the new laws.', 'Under SB-261, finance teams will need to assess and report on climate-related financial risks that could impact the organization\\u2019 s financial performance. This includes analyzing the potential effects of climate change on the company\\u2019 s operations, revenue streams, and long-term financial health. Finance will need to work closely with procurement and supply chain departments to understand the logistical and financial risks across operations. The urgency of these regulations puts increasing pressure on finance leaders, who remain at the forefront of ensuring compliance across their organizations.', 'However, quantifying and reporting climate-related risks is still an evolving area. Teams will need to develop new skills and frameworks to model potential climate impacts. To meet the challenge, finance departments need to budget accordingly to include new reporting systems, data collection processes, external audits, and other sustainability initiatives.', 'Procurement will need to reassess their sourcing strategies to prioritize sustainable suppliers that align with the organization\\u2019 s ESG goals. This may involve setting new criteria during supplier selection or bidding events, including reduced emissions, eco-friendly materials, or water conservation practices.', 'Routine auditing of suppliers will also be paramount to ensure there are no violations of any compliance laws or near-term climate risks that may impact the organization\\u2019 s operations. For example, if an organization gets an alert from their supplier risk monitoring system that there\\u2019 s increased flooding for their rubber supplier in South India, they may choose to seek an alternative supplier or make note of the risk in their climate-related financial report for SB-261.', 'Under SB-253, supply chain departments will need to work with procurement teams to track Scope 3 emissions from transportation, logistics, and suppliers. With many players across global supply chains, tracking Scope 3 emissions can be challenging. However, there are AI-driven tools that can help collect, process, and analyze this data.', 'For SB-261, supply chain teams will need to work with finance to analyze how potential climate disruptions \\u2014 like floods, droughts, and extreme weather events \\u2014 will impact operations and develop strategies to combat them. Modeling technology that includes a digital twin of a company\\u2019 s supply chain gives teams the power to test different climate-related scenarios and adjust logistics, distribution centers, and shipping routes to combat these threats and find more sustainable transportation and network solutions.', 'California Governor Gavin Newsom proposed pushing back the Scope 1 and 2 disclosure deadlines to 2028, and the Scope 3 disclosure deadline to 2029, but those changes were not included in the amendments signed into law in September 2024. With legal challenges and uncertainties around reporting criteria, implementation may still be delayed.', 'These laws are designed to accelerate sustainability initiatives that curb greenhouse emissions and promote transparency of corporate social responsibility projects. If companies don\\u2019 t have visibility and control across their supply chain, supplier network, and spending activity, they will find it nearly impossible to meet the disclosure requirements in California. Many still struggle with disjointed systems and highly manual processes that silo data and prevent cross-department collaboration.', 'It\\u2019 s important to centralize operations and data on one platform to improve visibility and control over ESG-related activities. Companies should seek to:', 'Now is the time to prepare your data structure and process workflows, even if the regulations are further delayed.', 'Microsoft is on an ambitious mission to be carbon-negative by 2030. The company hopes to reach that goal while opening hundreds of new data centers nationwide, a logistically energy-intensive process since IT hardware is often heavy and requires special packaging. To balance the conflicting goals of fostering growth and reducing carbon emissions, Microsoft uses Coupa Supply Chain Design & Planning. The team tests various supply chain scenarios for future inventory positioning, freight consolidation opportunities, and optimized distribution center locations. By seeing tradeoffs between service reliability, cost, and emissions, Microsoft makes data-driven decisions that support its overall business goals. So far, Coupa\\u2019 s solution empowered Microsoft to slash North American trucking emissions by 60% without compromising speedy deliveries. The same approach is being replicated in Europe and other world regions.', 'Companies of all sizes trust Coupa to help them drive more sustainable practices. With Coupa\\u2019 s # 1 AI Total Spend Management platform, you can:', 'While there are still uncertainties on how California\\u2019 s new regulations will be implemented, it\\u2019 s a sure sign that these types of laws will become mainstream across the nation. To meet the challenge, companies should prepare a robust data infrastructure that enables finance, procurement, and supply chain leaders to gain greater visibility, accelerate sustainable decisions, and mitigate risk.', 'As a company headquartered in California, we\\u2019 re also focused on meeting these new regulations as part of our overall path to net-zero emissions by 2041. Our robust climate strategy ensures we serve as a sustainable supplier for our global customers while also helping organizations develop their own sustainability programs. Read our 2024 ESG Report to learn how we\\u2019 re reducing emissions significantly and integrating climate strategy into our overall business operations.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 187,\n        \"samples\": [\n          \"speedinvest\",\n          \"accenture\",\n          \"ciodive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16527,\n        \"samples\": [\n          \"https://news.mit.edu/2025/making-graphs-more-accessible-blind-low-vision-readers-0325\",\n          \"https://www.thefastmode.com/expert-opinion/43318-upleveling-omnichannel-how-ai-helps-contact-centers-move-from-reactive-to-proactive-service\",\n          \"https://sloanreview.mit.edu/article/the-genai-app-step-youre-skimping-on-evaluations/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12439,\n        \"samples\": [\n          \"['RoboticArm', 'Zillow', 'Robotics', 'SmartHome']\",\n          \"['Accountability', 'NaturalLanguageProcessing', 'Clustering', 'DrugDiscovery']\",\n          \"['Nanox', 'DeepLearning', 'MedicalImaging', 'MultimodalAI']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0c6b4044-b061-4802-a0ad-b494ef1e7dd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>content</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88571</td>\n",
              "      <td>Ricoh to provide customer support for Agility ...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['The Digit humanoid could work in distributio...</td>\n",
              "      <td>therobotreport</td>\n",
              "      <td>https://www.therobotreport.com/ricoh-provides-...</td>\n",
              "      <td>['Robotics', 'Video', 'BostonDynamics']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92022</td>\n",
              "      <td>MTV VMAs 2024: Live shopping is coming to the ...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['In this article', \"When viewers tune in to t...</td>\n",
              "      <td>cnbc</td>\n",
              "      <td>https://www.cnbc.com/2024/09/11/mtv-vmas-2024-...</td>\n",
              "      <td>['GenerativeAI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>81522</td>\n",
              "      <td>Open-source imagery is transforming investigat...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['Open-source online imagery can play a vital ...</td>\n",
              "      <td>theconversation</td>\n",
              "      <td>https://www.theconversation.com/open-source-im...</td>\n",
              "      <td>['Disinformation', 'Video', 'Deepfake', 'Infor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81521</td>\n",
              "      <td>With China seeking AI dominance, Taiwan’ s eff...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['Tensions between China, Taiwan and the U.S. ...</td>\n",
              "      <td>theconversation</td>\n",
              "      <td>https://www.theconversation.com/with-china-see...</td>\n",
              "      <td>['MilitaryAndDefense', 'Missiles', 'HighPerfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63808</td>\n",
              "      <td>Study links EV charging stations to increased ...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['Countries globally are rapidly transitioning...</td>\n",
              "      <td>phys</td>\n",
              "      <td>https://phys.org/news/2024-09-links-ev-station...</td>\n",
              "      <td>['Causality', 'Planning']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c6b4044-b061-4802-a0ad-b494ef1e7dd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c6b4044-b061-4802-a0ad-b494ef1e7dd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c6b4044-b061-4802-a0ad-b494ef1e7dd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0                                              title        date  \\\n",
              "0       88571  Ricoh to provide customer support for Agility ...  2024-09-11   \n",
              "1       92022  MTV VMAs 2024: Live shopping is coming to the ...  2024-09-11   \n",
              "2       81522  Open-source imagery is transforming investigat...  2024-09-11   \n",
              "3       81521  With China seeking AI dominance, Taiwan’ s eff...  2024-09-11   \n",
              "4       63808  Study links EV charging stations to increased ...  2024-09-11   \n",
              "\n",
              "                                             content           domain  \\\n",
              "0  ['The Digit humanoid could work in distributio...   therobotreport   \n",
              "1  ['In this article', \"When viewers tune in to t...             cnbc   \n",
              "2  ['Open-source online imagery can play a vital ...  theconversation   \n",
              "3  ['Tensions between China, Taiwan and the U.S. ...  theconversation   \n",
              "4  ['Countries globally are rapidly transitioning...             phys   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.therobotreport.com/ricoh-provides-...   \n",
              "1  https://www.cnbc.com/2024/09/11/mtv-vmas-2024-...   \n",
              "2  https://www.theconversation.com/open-source-im...   \n",
              "3  https://www.theconversation.com/with-china-see...   \n",
              "4  https://phys.org/news/2024-09-links-ev-station...   \n",
              "\n",
              "                                                tags  \n",
              "0            ['Robotics', 'Video', 'BostonDynamics']  \n",
              "1                                   ['GenerativeAI']  \n",
              "2  ['Disinformation', 'Video', 'Deepfake', 'Infor...  \n",
              "3  ['MilitaryAndDefense', 'Missiles', 'HighPerfor...  \n",
              "4                          ['Causality', 'Planning']  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# csv_path = '/content/drive/My Drive/CLT/ai_media_dataset_20250911.csv'\n",
        "csv_path = 'data/ai_media_dataset_20250911.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Od3x23Lrhl",
        "outputId": "e6ffdff3-8c8d-4aa8-bfa7-7ea06b57531f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16527, 7)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncfoiYZYL-y3"
      },
      "source": [
        "The dataset contains 16'527 observations with 7 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iSD0ruzKp73"
      },
      "source": [
        "### Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGIKzVZZK5I0",
        "outputId": "10ef98d5-89fe-4dde-a343-12c2ee062e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows: 0\n",
            "Number of duplicate titles: 0\n",
            "Number of duplicate content:9\n",
            "Number of duplicate URLs: 0\n"
          ]
        }
      ],
      "source": [
        "duplicate_rows = df[df.duplicated()]\n",
        "print(f\"Number of duplicate rows: {len(duplicate_rows)}\")\n",
        "\n",
        "title_duplicate = df[df.duplicated(subset='title')]\n",
        "print(f\"Number of duplicate titles: {len(title_duplicate)}\")\n",
        "\n",
        "content_duplicate = df[df.duplicated(subset ='content')]\n",
        "print(f\"Number of duplicate content:{len(content_duplicate)}\")\n",
        "\n",
        "url_duplicate = df[df.duplicated(subset ='url')]\n",
        "print(f\"Number of duplicate URLs: {len(url_duplicate)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xhcGYsGMgPQ"
      },
      "source": [
        "There are no duplicate rows, titles and urls. But there is duplicate content. We take a closer look at the duplicate content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfNLuK9QNYKp",
        "outputId": "edb2d821-a128-46fc-af7f-481097bd261d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Unnamed: 0                                              title  \\\n",
            "920         93651  Performance, Security FOMO Could Fuel The AI P...   \n",
            "933         93649  A Performance, Security FOMO Could Fuel The AI...   \n",
            "7070       105445  ProMat Show Planner: 2025 to be bigger and bet...   \n",
            "6354       105429  ProMat 2025 show planner: Bigger and better th...   \n",
            "5174       105395    Maximizing automated systems at Outdoor Network   \n",
            "2582       105328           Maximizing automation at Outdoor Network   \n",
            "9337        94172  Connecting the dots: how to use relationship n...   \n",
            "3300        94135  Connect the dots: how to use relationship netw...   \n",
            "3914       105357   Object and pedestrian detection solutions evolve   \n",
            "5178       105394  Object and pedestrian detection warehouse safe...   \n",
            "528          3230      Gen AI-Powered Reinvention: How APAC can Lead   \n",
            "568          3232      Generative AI Powered Strategy in APAC Region   \n",
            "4422       105373  Supply Chain Imperatives 2024 and Beyond - Sup...   \n",
            "13669      105728  Supply Chain Imperatives 2024 and Beyond - Mat...   \n",
            "10354       74288  meta-llama/Llama-4-Maverick-17B-128E-Instruct ...   \n",
            "10451       74290  meta-llama/Llama-4-Scout-17B-16E-Instruct · Hu...   \n",
            "7570        90838                             Top NFT Companies 2025   \n",
            "7582        90840               Top United States NFT Companies 2025   \n",
            "\n",
            "             date                                            content  \\\n",
            "920    2024-10-03  [\"“ You have to be careful where you position ...   \n",
            "933    2024-10-03  [\"“ You have to be careful where you position ...   \n",
            "7070   2025-02-01  ['As a premier global event for manufacturing ...   \n",
            "6354   2025-01-27  ['As a premier global event for manufacturing ...   \n",
            "5174   2025-01-06  ['It can be reassuring to think a mix of wareh...   \n",
            "2582   2024-11-04  ['It can be reassuring to think a mix of wareh...   \n",
            "9337   2025-03-16  ['It may sound like an exaggeration, but there...   \n",
            "3300   2024-11-16  ['It may sound like an exaggeration, but there...   \n",
            "3914   2024-12-02  ['Object and pedestrian detection and avoidanc...   \n",
            "5178   2025-01-06  ['Object and pedestrian detection and avoidanc...   \n",
            "528    2024-09-25  ['Over the past four years, the APAC region ha...   \n",
            "568    2024-09-25  ['Over the past four years, the APAC region ha...   \n",
            "4422   2024-12-12  ['Supply Chain Solutions hold Commerce Togethe...   \n",
            "13669  2025-06-08  ['Supply Chain Solutions hold Commerce Togethe...   \n",
            "10354  2025-04-01  ['The information you provide will be collecte...   \n",
            "10451  2025-04-02  ['The information you provide will be collecte...   \n",
            "7570   2025-02-08  ['ZORA is a group of individuals working towar...   \n",
            "7582   2025-02-09  ['ZORA is a group of individuals working towar...   \n",
            "\n",
            "               domain                                                url  \\\n",
            "920               crn  https://www.crn.com/news/ai/2024/performance-s...   \n",
            "933               crn  https://www.crn.com/news/ai/2024/performance-s...   \n",
            "7070   supplychain247  https://www.supplychain247.com/article/promat_...   \n",
            "6354   supplychain247  https://www.supplychain247.com/article/promat_...   \n",
            "5174   supplychain247  https://www.supplychain247.com/article/maximiz...   \n",
            "2582   supplychain247  https://www.supplychain247.com/article/maximiz...   \n",
            "9337           avaloq  https://www.avaloq.com/fr/Insights/blog/connec...   \n",
            "3300           avaloq  https://www.avaloq.com/resources/blog/connecti...   \n",
            "3914   supplychain247  https://www.supplychain247.com/article/object_...   \n",
            "5178   supplychain247  https://www.supplychain247.com/article/object_...   \n",
            "528         accenture  https://www.accenture.com/hk-en/insights/strat...   \n",
            "568         accenture  https://www.accenture.com/bg-en/insights/strat...   \n",
            "4422   supplychain247  https://www.supplychain247.com/virtual-2024/pa...   \n",
            "13669  supplychain247  https://www.supplychain247.com/summit-2025/pap...   \n",
            "10354     huggingface  https://huggingface.co/meta-llama/Llama-4-Mave...   \n",
            "10451     huggingface  https://huggingface.co/meta-llama/Llama-4-Scou...   \n",
            "7570          builtin   https://builtin.com/companies/type/nft-companies   \n",
            "7582          builtin  https://builtin.com/companies/type/nft-compani...   \n",
            "\n",
            "                                                    tags  \n",
            "920    ['Planning', 'Video', 'LanguageModel', 'Genera...  \n",
            "933    ['Planning', 'Video', 'LanguageModel', 'Genera...  \n",
            "7070                            ['Robotics', 'Planning']  \n",
            "6354                            ['Robotics', 'Planning']  \n",
            "5174                            ['Robotics', 'Planning']  \n",
            "2582                            ['Robotics', 'Planning']  \n",
            "9337                ['GraphAnalytics', 'Accountability']  \n",
            "3300                ['GraphAnalytics', 'Accountability']  \n",
            "3914   ['Robotics', 'ObjectRecognition', 'GenerativeA...  \n",
            "5178   ['Robotics', 'ObjectRecognition', 'GenerativeA...  \n",
            "528    ['GenerativeAI', 'SyntheticData', 'Accountabil...  \n",
            "568    ['GenerativeAI', 'SyntheticData', 'Accountabil...  \n",
            "4422                                  ['Accountability']  \n",
            "13669                                 ['Accountability']  \n",
            "10354  ['HuggingFace', 'Llama', 'LargeLanguageModel',...  \n",
            "10451  ['HuggingFace', 'Llama', 'LargeLanguageModel',...  \n",
            "7570           ['Metaverse', 'Gaming', 'Accountability']  \n",
            "7582           ['Metaverse', 'Gaming', 'Accountability']  \n"
          ]
        }
      ],
      "source": [
        "duplicate_content_rows = df[df.duplicated(subset=['content'], keep=False)].sort_values(by='content')\n",
        "print(duplicate_content_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T45dGaYEPzB3"
      },
      "source": [
        "As there are only nine duplicate rows, we can easily review the output above manually to identify the following patterns:\n",
        "\n",
        "* **Titles:** There are slight differences that do not seem relevant regarding content (for example, with and without an article, or with and without a year).\n",
        "* **Dates:** Publication dates vary, sometimes differing by several months.\n",
        "* **Domains:** The source domain remains consistently identical across all duplicates.\n",
        "* **URLs:** Links vary occasionally, typically reflecting different regional paths or language preferences.\n",
        "* **Tags:** The assigned tags are always identical.\n",
        "\n",
        "\n",
        "Since the duplicated content consistently originates from the same source domain, we have decided to retain only the earliest published instance of each text. This approach ensures we capture the relevant information precisely when it first emerged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Hr3gJvcOS-vt",
        "outputId": "bd7b7602-e4d6-4e2e-fa69-83253387d413"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_unique\",\n  \"rows\": 16518,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27026,\n        \"min\": 6,\n        \"max\": 109492,\n        \"num_unique_values\": 16518,\n        \"samples\": [\n          103160,\n          78203,\n          106213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16518,\n        \"samples\": [\n          \"Is AI Public Enemy # 1 for Writers?\",\n          \"AI for Customer Success ( KPIs and Tools)\",\n          \"How I 'd Learn AI in 2025 ( If I Could Start Over)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-09-11 00:00:00\",\n        \"max\": \"2025-08-24 00:00:00\",\n        \"num_unique_values\": 347,\n        \"samples\": [\n          \"2025-07-30 00:00:00\",\n          \"2025-01-03 00:00:00\",\n          \"2025-08-02 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16518,\n        \"samples\": [\n          \"['We in Vanguard UX craft experiences that give our clients the best chance of investment success. This forum offers our latest thinking on the strategy, culture, & leadership from our deeply passionate Vanguard UX crew.', 'As a professional content writer with a touch of anxiety, I was pretty rattled as soon as I got my first whiff of AI-generated prompts and dialogue. It was bad enough watching videos of robotic dogs running around in uniform like quick-twitch tanks, but now I\\u2019 m stressing over my livelihood being threatened ( at least until the robot takeover officially begins).', 'It\\u2019 s not an original thought to be concerned about AI replacing us as writers. I remember sitting on the beach a few years back and my brother asking if I was worried about ChatGPT.', '\\u201c It\\u2019 s so great. I use it to write job descriptions for potential candidates. \\u201d', 'My first thought was: Bro, you\\u2019 re a sales executive. Your job has been a piece of cake since ecommerce allowed consumers to buy online.', 'But instead of scoffing, I took a step back and thought about how his specialized skills are required in his role, even with the modern benefits of ecommerce. He builds long-term relationships with businesses that can mutually benefit both companies. He coaches a team of sales associates that he can trust to create connections and manage sales across the country. And while technical innovations have revolutionized the industry, so many responsibilities of the role simply can\\u2019 t be replaced.', 'It\\u2019 s not all that different from how AI can be a supplement for us to create great content.', 'Side note: I follow big bro on LinkedIn and those job descriptions need a second set of eyes\\u2026 human eyes.', 'Before that conversation with my brother \\u2014 and long before I tried out Writer, the artificial intelligence tool our UX team at Vanguard uses \\u2014 hip-hop was a huge passion of mine. Ever since I unwrapped my now all-time favorite album on Christmas morning in 2003, I was hooked. There was something inspiring about that southern-based rap duo\\u2019 s unique flavor and lyrical prowess. I enjoyed writing, but after listening to that album, I felt cool because I enjoyed writing.', 'Working on music became a creative outlet that boosted my mental well-being. My career wasn\\u2019 t quite as lucrative as my lyrics may have insinuated, but I did eventually get to the point of performing in front of small local crowds.', 'I collaborated with a producer who doubled as a \\u201c hype person \\u201d \\u2014 someone who would bop around on stage with me and help keep the crowd engaged with the performance. He did more than that, though. His support gave me the confidence, as a socially awkward person, to get up there and present my art. He reigned me in when my metaphors were too out there or when my content was too personal. He understood crowds and how to use ad-libs to get their attention.', 'Years later, as an opportunity arose to test out generative AI in my work as a UX writer, I realized there was a connection between the role of tools like Writer and the benefits of working with a \\u201c hype person. \\u201d This realization changed my entire perspective on AI because while I could acknowledge the assistance it provided, I also understood my value in the partnership. Take that, big bro ( and future robot enemies)!', 'After my initial work with Writer, I was tasked with sharing my experience using it with our larger content team. A mild wave of anxiety washed over me when I realized it would be the largest audience I\\u2019 ve presented to in my current role. I logged right into Writer and typed the prompt, \\u201c Write me a concise speech about how AI can be a useful tool for content writers. \\u201d I continued tweaking the prompts until I had an introduction that would give the audience an idea of what Writer churns out.', 'I had to laugh because the output used more than one of the identifier words and phrases James Presbitero Jr. writes about in his post These Words Make it Obvious Your Text is Written by AI. I specifically remember the output including, \\u201c think of writing with AI as\\u2026 \\u201d and it referred to the practice as \\u201c transformative. \\u201d', 'The tone of the Writer-generated speech felt, for lack of a better word, robotic. With generative AI creating content through trends, we can expect to see a lot of repetition. Even when I asked Writer to add some humor, it just peppered in, \\u201c you know what I mean? \\u201d throughout.', 'Using Writer gave me confidence in two ways. First, by helping me ease into a presentation I was a feeling nervous about. Second, it showed me that as much as we prompt AI to get our content the way we want it, it will lack human creativity, emotion, and refreshing themes.', 'The first time I used Writer, I was working on a change management banner to inform clients their dashboard experience was going to look a little different.', 'Do you ever write something you like, and it gets stuck in your brain to the point where it feels impossible to edit, tweak, and perfect? That\\u2019 s where I was with the banner content. I felt good. My content was complete.', 'It was reminiscent of my hip-hop career when I would write world-changing metaphors or add some slick little details that I knew would really get the people going. Luckily, some of those never made it into production, thanks to my hype person informing me that those lines were only landing with me.', 'So, while working on that banner, I decided to boot up Writer and request content that would help clients navigate a refreshed dashboard. The suggestions weren\\u2019 t the best, but some of the themes opened me up to new ideas too, which helped me craft a stronger banner that would resonate better with our clients.', 'One of the new features we were adding to our updated dashboard was a card that summarized some client account data. While I have to be intentionally vague about the data, I can say that creating a title for this chart was giving me trouble.', 'There was some inconsistency around the terminology for this data set throughout our site. After some competitive analysis, I realized there were other sites that were using inconsistent terminology as well. Before we started our research initiative, I asked Writer what it would name the feature. If Writer is constantly learning and pulling data from every corner of the internet, it should know what would resonate with clients the most.', 'Following our client testing, it was clear that one title stood out more than the others. That selection happened to be my original recommendation, as well as Writer\\u2019 s suggestion. While it\\u2019 s a positive sign that Writer offered up the same title we landed on, we wouldn\\u2019 t have chosen it based on that fact alone. It was, however, nice to have some backup that correlated with our findings.', 'As UX-ers, it\\u2019 s our job to use sound data as much as possible to create the best content and experience for our clients, but sometimes we get in the zone. We\\u2019 re up on stage and we\\u2019 re doing our thing \\u2014 spitting bars, writing content, drafting designs. Sometimes we need that hype person to ensure the crowd is being involved. Throwing those hands up and side to side. Singing along with the hooks. Understanding the content we\\u2019 re presenting to them.', 'Writing for UX is so data-driven, hyper-collaborative, and detail-oriented that it can feel less than creative at times, but there\\u2019 s certainly an art to it. Even with increased opportunities to use generative AI in our work process, we\\u2019 re ultimately still the artists. As much as our hype person can help us present our art in ways that enhances the experience, the show doesn\\u2019 t happen without us.', 'Now excuse me while I install this recording booth in my doomsday bunker.', 'We in Vanguard UX craft experiences that give our clients the best chance of investment success. This forum offers our latest thinking on the strategy, culture, & leadership from our deeply passionate Vanguard UX crew.']\",\n          \"['We\\u2019 ve all needed a quick solution\\u2014whether it\\u2019 s resetting a password or troubleshooting an issue. That\\u2019 s where the Salesforce Help page comes in. With over 60 million visits a year, customers rely on it for everything from troubleshooting to developer support. But what if getting the right help was faster and more personalized?', 'Salesforce saw an opportunity to enhance the customer experience by integrating AI into customer success. By using Agentforce, they streamlined routine requests and freed up support reps to focus on more complex issues. Salesforce saw an opportunity to enhance self-service, reduce wait times, and free up reps to focus on high-value, one-on-one support.', 'Today, AI plays a critical role in transforming key customer success metrics for CX leaders. It helps businesses predict customer needs, streamline experiences, and boost engagement. By analyzing vast data sets, AI enables CX leaders to optimize key performance indicators ( KPIs) like never before.', 'Agentforce provides always-on support to employees or customers. Learn how Agentforce can help your company today.', 'It\\u2019 s not just technology giants that are benefiting from AI. Organizations of all shapes and sizes are using AI tools to transform customer experience and improve KPIs.', 'OpenTable, a leader in restaurant tech, helps 60k+ restaurants fill 1.7 billion seats a year. With AI and Agentforce, Opentable autonomously handles routine tasks such as reservation changes and loyalty point redemptions. This allows agents to focus on delivering exceptional service in more complete situations.', 'The Adecco Group is one of the world\\u2019 s largest talent solutions companies. They process 300 million applications per year and place 1 million people daily for some of the world\\u2019 s largest companies. With AI, Adecco Group autonomously handles administrative work freeing up recruiters to focus on candidates.', 'At UserTesting, a company that provides a platform for rapid customer feedback on digital experiences, they are using AI to identify common themes in user interactions.', '\\u201c Instead of having to watch hours of videos, taking notes, and trying to find the important parts, AI will tell you what is common and echoing from all of these conversations, \\u201d Michelle Engel, Chief Product Officer at UserTesting, shared on a recent episode of Experts of Experience. AI has helped her team save time and enhance the quality of insights gathered.', 'AI\\u2019 s ability to analyze data, recognize patterns, and predict trends through business intelligence systems has a powerful twofold effect. 1) It directly improves the customer experience and 2) It is enhancing the way metrics are measured.', 'First, it helps create more seamless, personalized interactions for customers, leading to better engagement, higher satisfaction, and stronger loyalty. At the same time, AI tools make it easier to track and measure key metrics with precision. They can analyze vast amounts of data in real-time, offering deeper insights into trends and areas for improvement. This combination of enhanced experiences and better measurement gives businesses a strong advantage in refining their strategies and achieving their metric goals.', 'Before diving too far into what tools to consider, here\\u2019 s a quick overview of the metrics that matter most and how AI can help improve them.', 'Whether it\\u2019 s NPS, CLV, Churn, or any other KPI that you are looking to improve, there are several ways you can fold AI in to help \\u2013 let\\u2019 s dive into some specific tools and use cases.', 'Learn how to fast-track your Agentforce implementation and drive long-term success.', 'Below, we break down common Customer Experience challenges and pair them with AI tools that provide effective solutions, offering a closer look at their capabilities and impact.', 'Understanding and predicting customer behavior allows businesses to anticipate needs and offer proactive solutions. Predictive analytics leverages historical and real-time data to forecast actions such as purchasing patterns, potential churn, and product preferences.', 'These tools use machine learning algorithms to identify trends and provide actionable insights into customer behavior. Advanced platforms integrate seamlessly with CRM systems to continuously update customer profiles.', 'Use Case Example: Saks is enhancing the customer experience by adding a personalization strategy by utilizing first-party data and AI to create a highly customized shopping experience across digital, mobile, and in-store touch points, transforming the luxury shopping experience and fostering loyalty.', 'AI-powered personalization tools analyze behavior, preferences, and historical data to tailor customer interactions across channels. These tools make each customer feel uniquely understood and valued.', 'These AI tools analyze browsing history, purchase data, and customer feedback to deliver real-time content recommendations, personalized email campaigns, or targeted promotions.', 'Use Case Example: Nationwide is taking personalization to the next level. By using AI and integrating with digital asset management and customer data platforms, they\\u2019 re making customer experiences more tailored than ever. These upgrades mean smarter, more targeted campaigns and web experiences that feel custom-built for each customer. It\\u2019 s all about creating connections that keep customers engaged \\u2014 and coming back.', 'AI-powered sentiment analysis tools use NLP to analyze chat logs, emails, and social media, uncovering customer emotions and dissatisfaction early. By processing vast amounts of feedback, these platforms provide real-time insights and visual dashboards, helping businesses proactively address concerns and reduce churn.', '\\u201c We can generate a lot of data around how the member is experiencing and navigating the platform without them telling us, \\u201d shared Sarah Parker, SVP of Customer Success at BetterUp, on Experts of Experience.', '\\u201c In the traditional days, you\\u2019 re waiting for the negative NPS, a CAT survey, or an angry customer email to let you know there\\u2019 s a problem. Now, there\\u2019 s a lot that we can do to detect problems before they arise. \\u201d', 'AI-powered Sentiment Analysis Software and VoC Analytics Platforms help businesses proactively reduce churn and enhance customer insights. Using natural language processing ( NLP), these tools analyze text and audio data to assign sentiment scores, enabling teams to identify dissatisfaction early and prioritize outreach. By processing vast amounts of customer feedback, they uncover key themes and trends, refining messaging and improving engagement strategies. Many platforms also offer dashboards to visualize sentiment shifts over time, empowering businesses to make data-driven decisions that enhance customer experience.', 'Use Case Example: A hospitality brand reviews feedback across platforms like TripAdvisor and Google to identify recurring complaints about check-in wait times, prompting operational changes to address delays.', 'Create an Agentforce Service Agent to assist with recommendations and bookings.', 'CX Metrics Impacted: First-Response Time, Resolution Time, Operational Efficiency.', 'Automation tools streamline repetitive tasks, ensuring quicker resolutions and freeing up agents to handle complex inquiries. This approach improves efficiency and maintains consistent quality across all customer interactions.', 'Autonomous agents are an advanced form of AI that can independently execute a series of tasks, and learn as they go.', 'Use Case Example: A retail company trains Agents to answer 70% of customer inquiries, including product availability and returns policies. For unresolved issues, the Agent forwards cases with context, reducing agent workload.', 'CX Metrics Impacted: First-Contact Resolution Rate, Customer Effort Score ( CES), Operational Costs.AI Tools Enhancing Customer Success', 'AI tools empower customers to solve problems independently, reducing dependency on agents while maintaining high-quality service.', 'Agentforce can connect customers to relevant answers and provide personalized support from anywhere at scale.', 'Use Case Example: See how financial institutions can enhance customer satisfaction and deflect cases with AI-powered self-service tools like Service Agent. This empowers customers by providing proactive support and quick resolutions to their inquiries.', 'As AI agents continue to evolve, their impact on customer success will only grow stronger. By leveraging AI-driven insights, CX leaders can proactively address customer needs, refine engagement strategies, and drive meaningful improvements in key performance metrics. The ability to predict behaviors, personalize experiences, and streamline operations positions AI as an essential tool for delivering exceptional customer experiences. Businesses that embrace AI will not only optimize their KPIs but also build stronger, more loyal customer relationships in the long run.', 'As a Bay Area native with a multicultural background ( Chinese and Mexican), I bring a unique perspective to the world of B2B marketing. With over a decade of experience in marketing, I specialize in digital campaigns, SEO, product launches, and content marketing. My expertise extends beyond... Read More marketing\\u2014having previously worked as a Salesforce Administrator for Sales Cloud, I combine deep technical knowledge with strategic marketing insight to create compelling, high-impact content.', 'Yes, I would like to receive the Salesforce 360 Highlights newsletter as well as marketing emails regarding Salesforce products, services, and events. I can unsubscribe at any time.', 'By registering, you confirm that you agree to the processing of your personal data by Salesforce as described in the Privacy Statement.', '\\u00a9 Copyright 2025 Salesforce, Inc. All rights reserved. Various trademarks held by their respective owners. Salesforce, Inc. Salesforce Tower, 415 Mission Street, 3rd Floor, San Francisco, CA 94105, United States']\",\n          \"['The world\\u2019 s leading publication for data science, AI, and ML professionals.', 'Today, more people than ever are trying to learn AI. Although there are countless free learning resources online, navigating this rapidly evolving landscape can be overwhelming ( especially as a beginner). In this article, I discuss how I\\u2019 d approach learning AI, given what I know now and the tools available today.', 'Given the wide range of backgrounds interested in AI these days, I\\u2019 ve tried to make this guide widely accessible. However, no guide can help everyone. Here are a few specific groups I have in mind.', 'About me \\u2013 I\\u2019 ve worked in AI for the past 6 years. I started as an AI researcher while getting my PhD, then eventually worked as a data scientist at Toyota. Although I still have a lot to learn, the approach below covers ( what I think are) the essentials based on my personal experience.', 'The guiding principle of this framework is to learn by doing. Each step outlines a clear and specific objective through which completion will naturally develop key skills. In other words, rather than reviewing a list of concepts and courses, each step is a task designed to force me to learn essential skills by completing it.', 'Here\\u2019 s an overview of the 5-step approach. Each step builds upon the ones before it.', 'If starting from zero, the first thing I would do is familiarize myself with modern AI tools i.e. ChatGPT, Claude, and the like. This is important because frequently using these models will give me a practical understanding of what they can and can\\u2019 t do and * * develop my ability to use them effectively through promptin * * g.', 'On a more meta level, these chat interfaces are incredible tools for learning AI ( or anything else, really). I\\u2019 d use it to explain confusing buzzwords and technical concepts ( e.g. LLM, tokens, API, RAG) and be sure to ask follow-up questions until I have a solid understanding of each idea. For those that don\\u2019 t click, I\\u2019 d seek alternative resources using Google search and YouTube.', 'Although I could go far with today\\u2019 s no-code AI tools, they are fundamentally limited. Namely, these tools can\\u2019 t be easily used to build custom solutions or process information in bulk. That\\u2019 s why the next thing I would do is install Python on my computer.', 'Python is the industry standard programming language for AI development. To get it installed, I\\u2019 d ask ChatGPT for step-by-step instructions. If I get stuck, I\\u2019 d come back to ChatGPT, explain the issue, and ask for additional guidance.', 'While using ChatGPT ( or any other AI assistant) in this way can streamline the process significantly, I would still take the time to understand each step of the process and ask follow-up questions as needed. This is an important habit to develop because it will avoid accumulating technical debt, which I\\u2019 ll have to pay later when something goes wrong.', 'Once I\\u2019 ve become comfortable using ChatGPT and installed Python on my machine, my next step would be to build a simple automation using Python. My approach to generating project ideas would be to think of things I consistently use ChatGPT for ( e.g. summarizing research articles), then try and automate it with Python.', 'This would require me to become familiar with OpenAI\\u2019 s Python API. So, I\\u2019 d start by reading their documentation and reviewing the example code there. Once I felt comfortable with the API, I\\u2019 d start writing Python code.', 'My first step would be to think through the steps of my automation. For example, if summarizing research papers, the steps might be:', 'If I got stuck, I\\u2019 d turn to ChatGPT for assistance. For instance, if I didn\\u2019 t know how to read PDFs into Python, I could ask ChatGPT for help. If it spits out code I don\\u2019 t understand, I\\u2019 d ask follow-up questions until I understand each line.', 'It ( again) is important that I take this approach to coding with ChatGPT because blindly copy-pasting code from it wouldn\\u2019 t teach me much. It would also accrue unforgiving technical debt. In other words, I\\u2019 d get short-term gains but would have to pay for them later via technical difficulties and headaches.', 'After Step 3 gets easy for me, I\\u2019 d seek out more sophisticated projects. Rather than simply making ChatGPT-like API calls, I\\u2019 d build a project that required me to use embedding models or to train a model myself.', 'For example, if I went with the RAG project, I\\u2019 d first educate myself on RAG by watching YouTube videos and reading blog posts. Then, I\\u2019 d break down the system\\u2019 s basic components and the steps to implement it. Finally, I\\u2019 d start coding the project, using ChatGPT as a co-pilot like Step 3.', 'Although I would have learned a lot about the technical side of AI from Steps 3 and 4, this is not sufficient for generating value with it. For that, I\\u2019 d need to use what I learned to solve real-world problems.', 'There are two ways to do this. I could, one, solve my own problem, or two, solve someone else\\u2019 s problem. Since I ( hopefully) already did the former way in Steps 3 and 4, here are a few different ways I\\u2019 d approach the latter.', 'Let\\u2019 s say I had graduated from college and wasn\\u2019 t quite confident enough to freelance yet so that leaves Option 1. I\\u2019 d start by making a list of people to reach out to. Ideal contacts would be small business owners or professionals working at a small to medium-sized business.', 'Then, I would craft a message like the one below and send it to everyone on my list via LinkedIn DM or email. If I struggle to find the right wording, I\\u2019 d use ChatGPT ( yet again) to help out.', 'Although AI entails an interdisciplinary collection of technical skills and knowledge, with today\\u2019 s tools and resources, it\\u2019 s never been more accessible. Here, I shared the 5-step approach I\\u2019 d take to learning it today.', 'That said, it\\u2019 s important to remember that learning ( itself) is hard. You will get confused, you will get frustrated, and you will question why you\\u2019 re putting yourself through this. However, if you are willing to see it through, you will be rewarded with clarity and knowledge, which is an amazing gift.', 'Your home for data science and Al. The world\\u2019 s leading publication for data science, data analytics, data engineering, machine learning, and artificial intelligence professionals.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 187,\n        \"samples\": [\n          \"speedinvest\",\n          \"bain\",\n          \"med-technews\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16518,\n        \"samples\": [\n          \"https://medium.com/vanguard-ux/is-ai-public-enemy-1-for-writers-1065a5e4ab77\",\n          \"https://www.salesforce.com/blog/ai-customer-success/\",\n          \"https://towardsdatascience.com/how-id-learn-ai-in-2025-if-i-knew-nothing-0496dc9ab54c/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12439,\n        \"samples\": [\n          \"['InformationRetrieval', 'SocialScoring']\",\n          \"['Reasoning', 'AIDemocratization', 'ChatGPT', 'HuggingFace', 'ChromaDB']\",\n          \"['GoogleCloud', 'LinuxFoundation', 'Databricks', 'Grafana', 'AzureAIFoundry', 'LargeLanguageModel', 'SmallLanguageModel']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_unique"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-54dff8ae-28e7-4679-b922-93a33492040a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>content</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88571</td>\n",
              "      <td>Ricoh to provide customer support for Agility ...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['The Digit humanoid could work in distributio...</td>\n",
              "      <td>therobotreport</td>\n",
              "      <td>https://www.therobotreport.com/ricoh-provides-...</td>\n",
              "      <td>['Robotics', 'Video', 'BostonDynamics']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>70996</td>\n",
              "      <td>AI Design Trends to Watch in 2025: From Photor...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['Artificial Intelligence ( AI) is rapidly tra...</td>\n",
              "      <td>geeksforgeeks</td>\n",
              "      <td>https://www.geeksforgeeks.org/ai-design-trends...</td>\n",
              "      <td>['Personalisation', 'NaturalLanguageProcessing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>104159</td>\n",
              "      <td>AIs generate more novel and exciting research ...</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['The first statistically significant results ...</td>\n",
              "      <td>newatlas</td>\n",
              "      <td>https://newatlas.com/technology/llm-novel-rese...</td>\n",
              "      <td>['LargeLanguageModel', 'ChatGPT', 'Anthropic',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>73625</td>\n",
              "      <td>Argonne's HPC/AI User Forum Wrap Up</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['As fans of this publication will already kno...</td>\n",
              "      <td>hpcwire</td>\n",
              "      <td>https://www.hpcwire.com/2024/09/11/argonnes-hp...</td>\n",
              "      <td>['HighPerformanceComputing', 'GenerativeAI', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>80150</td>\n",
              "      <td>Top 10: Supply Chain Optimisation Strategies</td>\n",
              "      <td>2024-09-11</td>\n",
              "      <td>['Supply chain optimisation has never been mor...</td>\n",
              "      <td>supplychaindigital</td>\n",
              "      <td>https://www.supplychaindigital.com/top10/top-1...</td>\n",
              "      <td>['Finetuning', 'Traceable', 'Accountability', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54dff8ae-28e7-4679-b922-93a33492040a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54dff8ae-28e7-4679-b922-93a33492040a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54dff8ae-28e7-4679-b922-93a33492040a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Unnamed: 0                                              title       date  \\\n",
              "0        88571  Ricoh to provide customer support for Agility ... 2024-09-11   \n",
              "26       70996  AI Design Trends to Watch in 2025: From Photor... 2024-09-11   \n",
              "27      104159  AIs generate more novel and exciting research ... 2024-09-11   \n",
              "28       73625                Argonne's HPC/AI User Forum Wrap Up 2024-09-11   \n",
              "29       80150       Top 10: Supply Chain Optimisation Strategies 2024-09-11   \n",
              "\n",
              "                                              content              domain  \\\n",
              "0   ['The Digit humanoid could work in distributio...      therobotreport   \n",
              "26  ['Artificial Intelligence ( AI) is rapidly tra...       geeksforgeeks   \n",
              "27  ['The first statistically significant results ...            newatlas   \n",
              "28  ['As fans of this publication will already kno...             hpcwire   \n",
              "29  ['Supply chain optimisation has never been mor...  supplychaindigital   \n",
              "\n",
              "                                                  url  \\\n",
              "0   https://www.therobotreport.com/ricoh-provides-...   \n",
              "26  https://www.geeksforgeeks.org/ai-design-trends...   \n",
              "27  https://newatlas.com/technology/llm-novel-rese...   \n",
              "28  https://www.hpcwire.com/2024/09/11/argonnes-hp...   \n",
              "29  https://www.supplychaindigital.com/top10/top-1...   \n",
              "\n",
              "                                                 tags  \n",
              "0             ['Robotics', 'Video', 'BostonDynamics']  \n",
              "26  ['Personalisation', 'NaturalLanguageProcessing...  \n",
              "27  ['LargeLanguageModel', 'ChatGPT', 'Anthropic',...  \n",
              "28  ['HighPerformanceComputing', 'GenerativeAI', '...  \n",
              "29  ['Finetuning', 'Traceable', 'Accountability', ...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "df_sorted = df.sort_values(by='date', ascending=True)\n",
        "df_unique = df_sorted.drop_duplicates(subset = 'content', keep = 'first')\n",
        "\n",
        "df_unique.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx9bvbrAUKlH",
        "outputId": "9f4700fa-1773-4251-e1fc-dd1e43751119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16518, 7)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPlvnoZLUSQd",
        "outputId": "d9aa876f-ee29-49ab-c7ab-16f7ebd3a358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate content:0\n"
          ]
        }
      ],
      "source": [
        "df_unique_content_duplicate = df_unique[df_unique.duplicated(subset ='content')]\n",
        "print(f\"Number of duplicate content:{len(df_unique_content_duplicate)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK2S-aFEUgGu"
      },
      "source": [
        "We successfully removed duplicate rows. Checking for shape confirmed that 9 rows were removed as well as checking for duplicate content again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRb7cASDViPu"
      },
      "source": [
        "### Handling missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zsScKeAVmCe"
      },
      "source": [
        "Firstly, we check for missing values. We double check with different methods:\n",
        "- **NA-Values**: Values that are actually missing and indicated as missing in the data\n",
        "- **Empty string**: Missing values might not be identified because they are empty strings.\n",
        "- **Placeholders**: Instead of an empty value, placeholders like \"N/A\" might be used. We check for the most common ones.\n",
        "- **Empty Lists**: Tags are saved as lists. We check for empty lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMrARPS_VowE",
        "outputId": "fecb6f79-b4e9-4171-eae7-2b353d378d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of NA-values: 0\n",
            "Number of empty strings: 0\n",
            "Number of placeholders: 0\n",
            "Empty tags count: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for NA-values\n",
        "missing_values_NA = df_unique.isna()\n",
        "print(f\"Number of NA-values: {missing_values_NA.sum().sum()}\")\n",
        "\n",
        "# Check for empty strings\n",
        "text_columns = df_unique.select_dtypes(include = ['object', 'string']).columns\n",
        "empty_strings = df_unique[text_columns].apply(lambda col: col.str.strip() == '')\n",
        "print(f\"Number of empty strings: {empty_strings.sum().sum()}\")\n",
        "\n",
        "# Check for placeholders\n",
        "placeholders = ['N/A', 'n/a', 'null', 'Null', 'none', 'None', 'unknown', 'Unknown', '-']\n",
        "placeholder_values = df_unique.isin(placeholders)\n",
        "print(f\"Number of placeholders: {placeholder_values.sum().sum()}\")\n",
        "\n",
        "# Check for empty lists\n",
        "empty_tags_count = (df_unique['tags'] == '[]').sum()\n",
        "print(\"Empty tags count:\", empty_tags_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGMnRUgamWH"
      },
      "source": [
        "There are no missing values in this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l19kOY4hbac_"
      },
      "source": [
        "### Normalize Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jvsObmicCbS"
      },
      "source": [
        "We create a function that cleans the text in regards of\n",
        "- **Removal of html tags**: All content within brackets < > is removed to strip away any residual web formatting.\n",
        "- **Replacing accented characters**: We use the unidecode library to replace all characters with accents (e.g., \"é\", \"ö\") with their closest ASCII equivalent (\"e\", \"o\") for better consistency.\n",
        "- **Casing**: We transform the entire text to lower-case letters to ensure that words like \"Tech\" and \"tech\" are treated as the same token.\n",
        "- **Removal of emojis**: WW remove all emoji-like patterns and special Unicode symbols that do not add semantic value to the text analysis.\n",
        "- **Removal of irrelevant symbols**: We delete all symbols that are not letters, numbers, or spaces, replacing them with a single space to prevent words from merging.\n",
        "- **Removal of white space**: We collapse multiple spaces into one and strip leading or trailing white spaces from the text.\n",
        "\n",
        "For this, we use Regex expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rGeyA4q-cx77"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Check if value is text\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # HTML-tags\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "    # Accented characters\n",
        "    text = unidecode.unidecode(text)\n",
        "\n",
        "    # Casing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Emoji patterns\n",
        "    emojis_pattern = re.compile(pattern=\"[\"\n",
        "                        u\"\\U0001F600-\\U0001F64F\"\n",
        "                        u\"\\U0001F300-\\U0001F5FF\"\n",
        "                        u\"\\U0001F680-\\U0001F6FF\"\n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                        u\"\\U00002500-\\U00002BEF\"\n",
        "                        u\"\\U00002702-\\U000027B0\"\n",
        "                        u\"\\U000024C2-\\U0001F251\"\n",
        "                        u\"\\U0001f926-\\U0001f937\"\n",
        "                        u\"\\U00010000-\\U0010ffff\"\n",
        "                        u\"\\u2640-\\u2642\"\n",
        "                        u\"\\u2600-\\u2B55\"\n",
        "                        u\"\\u200d\"\n",
        "                        u\"\\u23cf\"\n",
        "                        u\"\\u23e9\"\n",
        "                        u\"\\u231a\"\n",
        "                        u\"\\ufe0f\"\n",
        "                        u\"\\u3030\"\n",
        "                    \"]+\", flags=re.UNICODE)\n",
        "    text = emojis_pattern.sub(r'', text)\n",
        "\n",
        "    # Symbols\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "    # Spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrGu2Y4eXiO"
      },
      "source": [
        "We now apply the function to the columns title and content. We leave the columns url and tags untouched because:\n",
        "- **URL**: This doesn't add any information regarding the trend analysis but the url will not work anymore once the symbols are removed.\n",
        "- **Tags**: If we remove all symbols at once, two words that are one tag (like \"Machine Learning\") will be seperated from one another. So we have to normalize it separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHi7uxre0Oc",
        "outputId": "f7912c89-d3c9-4b6b-add5-dd0da3889c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Unnamed: 0                                              title       date  \\\n",
            "0        88571  ricoh to provide customer support for agility ... 2024-09-11   \n",
            "26       70996  ai design trends to watch in 2025 from photore... 2024-09-11   \n",
            "27      104159  ais generate more novel and exciting research ... 2024-09-11   \n",
            "28       73625                argonne s hpc ai user forum wrap up 2024-09-11   \n",
            "29       80150        top 10 supply chain optimisation strategies 2024-09-11   \n",
            "\n",
            "                                              content              domain  \\\n",
            "0   the digit humanoid could work in distribution ...      therobotreport   \n",
            "26  artificial intelligence ai is rapidly transfor...       geeksforgeeks   \n",
            "27  the first statistically significant results ar...            newatlas   \n",
            "28  as fans of this publication will already know ...             hpcwire   \n",
            "29  supply chain optimisation has never been more ...  supplychaindigital   \n",
            "\n",
            "                                                  url  \\\n",
            "0   https://www.therobotreport.com/ricoh-provides-...   \n",
            "26  https://www.geeksforgeeks.org/ai-design-trends...   \n",
            "27  https://newatlas.com/technology/llm-novel-rese...   \n",
            "28  https://www.hpcwire.com/2024/09/11/argonnes-hp...   \n",
            "29  https://www.supplychaindigital.com/top10/top-1...   \n",
            "\n",
            "                                                 tags  \n",
            "0             ['Robotics', 'Video', 'BostonDynamics']  \n",
            "26  ['Personalisation', 'NaturalLanguageProcessing...  \n",
            "27  ['LargeLanguageModel', 'ChatGPT', 'Anthropic',...  \n",
            "28  ['HighPerformanceComputing', 'GenerativeAI', '...  \n",
            "29  ['Finetuning', 'Traceable', 'Accountability', ...  \n"
          ]
        }
      ],
      "source": [
        "df_clean = df_unique.copy()\n",
        "\n",
        "cols_to_clean = ['title', 'content']\n",
        "\n",
        "for col in cols_to_clean:\n",
        "    df_clean[col] = df_clean[col].apply(clean_text)\n",
        "\n",
        "print(df_clean.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwkl3v1i6ff"
      },
      "source": [
        "We quickly check if there are empty strings now, because there might have been content or titles only consisting of symbols."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3aGP9nQi23u",
        "outputId": "cde57ef5-bc03-4ec3-9b14-3e14ba2e8f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty Values after Cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "empty_after_cleaning = (df_clean[cols_to_clean] == '')\n",
        "print(\"Empty Values after Cleaning:\", empty_after_cleaning.sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ_iSuwZiGq3"
      },
      "source": [
        "Now we handle the Tags separately: Lower casing and transform to list instead of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADm1_OVwiazw",
        "outputId": "5ddcbd76-fd25-4fab-92ef-bca33d71d735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                     [robotics, video, bostondynamics]\n",
            "26    [personalisation, naturallanguageprocessing, c...\n",
            "27    [largelanguagemodel, chatgpt, anthropic, claud...\n",
            "28    [highperformancecomputing, generativeai, robot...\n",
            "29    [finetuning, traceable, accountability, roboti...\n",
            "Name: tags, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df_clean_tag = df_clean.copy()\n",
        "\n",
        "# Transform strings into real Python lists\n",
        "df_clean_tag['tags'] = df_clean_tag['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# 3. Explode the list, normalize the text, and group it back\n",
        "df_clean_tag['tags'] = (\n",
        "    df_clean_tag['tags']\n",
        "    .explode()\n",
        "    .str.lower()\n",
        "    .str.strip()\n",
        "    .groupby(level=0)\n",
        "    .apply(lambda x: [tag for tag in x.tolist() if pd.notna(tag)])\n",
        ")\n",
        "\n",
        "# check\n",
        "print(df_clean_tag['tags'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7e2gg5ylViZ"
      },
      "source": [
        "Finally, give the Dataframe a short name for further analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8GOwTAzQlb2F"
      },
      "outputs": [],
      "source": [
        "df_final = df_clean_tag.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_S_jcxulpbl"
      },
      "source": [
        "## 1.2 Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk5G5Q-XlvSR"
      },
      "source": [
        "*Done by: XXX  - Checked by: XXX*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rN2hrQiAPjS"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I48UVxJJAxpU"
      },
      "source": [
        "For tokenization, we use spaCy. We only tokenize those columns, that contain text, namely title and content. We do not tokenize the other columns:\n",
        "\n",
        "\n",
        "*   **Date**: Is not in text format.\n",
        "*   **Domain**: This is a categorical identifier and does not add value to the analysis of the content.\n",
        "*   **URL**: This would destroy the functionality of the url.\n",
        "*   **Tags**: We already transformed the tags into a list of strings. Therefore, they are technically already tokenized in a way that respects the specific terminology. If we actually tokenized these values, we would separate key words belonging together like \"machine\" \"learning\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IjBCDmYVA1sl"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "cols_to_tokenize = ['title', 'content']\n",
        "\n",
        "df_token = df_final.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4m1XRuvQ9Bw"
      },
      "source": [
        "Because regular tokenization with spacy took a very long time (we interrupted after 25 minutes), we asked Gemini for a way to reduce the time. Using nlp.pipe as well as turning off tagger, parser, ner and lemmatizer were suggested, resulting in a processing time of approx. 28 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b46qHH-JQyiX",
        "outputId": "00d78c4f-3a56-403a-a802-b0c4bbf84ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing title...\n",
            "Tokenizing content...\n"
          ]
        }
      ],
      "source": [
        "# Optimized Tokenization\n",
        "for col in cols_to_tokenize:\n",
        "    print(f\"Tokenizing {col}...\")\n",
        "    # nlp.pipe takes a list of strings and processes them in batches\n",
        "    # 'disable' turns off everything we don't need for simple tokens\n",
        "    df_token[f'{col}_token'] = [\n",
        "        [token.text for token in doc]\n",
        "        for doc in nlp.pipe(\n",
        "            df_token[col].astype(str),\n",
        "            batch_size=100,\n",
        "            disable=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\"]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "print(\"Tokenization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k_2nRncYZaCi"
      },
      "outputs": [],
      "source": [
        "print(df_token.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA3Sw1NgZiyX"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92_6uj0IZ21b"
      },
      "source": [
        "For this, we equally asked Gemini for a time efficient method. It took approx. 35 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkReRxAXZllW"
      },
      "outputs": [],
      "source": [
        "# Optimized Lemmatization\n",
        "for col in cols_to_tokenize:\n",
        "    print(f\"Lemmatizing {col}...\")\n",
        "    df_token[f'{col}_lemma'] = [\n",
        "        [token.lemma_ for token in doc]\n",
        "        for doc in nlp.pipe(\n",
        "            df_token[col].astype(str),\n",
        "            batch_size=100,\n",
        "            disable=[\"parser\", \"ner\"] # parser and ner are the slowest parts\n",
        "        )\n",
        "    ]\n",
        "\n",
        "print(\"Lemmatization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMP8hM-P911N"
      },
      "source": [
        "###Stop word removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXACyp109025"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWpGVTVD-FO9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpuXJlAsno2f"
      },
      "source": [
        "## 1.3 EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJGG_hMCnraP"
      },
      "source": [
        "*Done by: XXX  - Checked by: XXX*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKZMrS57nxFC"
      },
      "source": [
        "## 1.4 Entity and Relationship Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggtoQsHBn0gi"
      },
      "source": [
        "*Done by: XXX  - Checked by: XXX*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySxUMzBAn5jx"
      },
      "source": [
        "## 1.5 Knowledge Graph Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XKqNYaHn8gE"
      },
      "source": [
        "*Done by: XXX  - Checked by: XXX*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEQyUAaln9U1"
      },
      "source": [
        "## 1.6 Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwhxsxGIoBYu"
      },
      "source": [
        "*Done by: XXX  - Checked by: XXX*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
